<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Research</title>
	<link rel="stylesheet" href="../base.css">
	<link rel="stylesheet" href="./style.css">
</head>
<body>
	<nav class="navbar">
		<ul class="navlinks">
			<li><a href="../">Home</a></li><li><a href="../projects/">Projects</a></li><li><a href="../research/">Research</a></li><li><a href="../contributions/">Contributions</a></li><li><a href="../experience/">Experience</a></li>
		</ul>
	</nav>
	<section class="main">
		<div class="paper-pane">
			<a href="" target="_blank"><img class="thumbnail" src="../images/papers/camcps.png" alt=""></a>
			<div class="paper-description">
				<h1><a class="paper-title" href="procedural-planets/">Comparative Analysis of Different Methods for Classifying Polychromatic Sketches</a></h1>
				<h2>Abstract</h2>
				<p>
					Image classification is a significant challenge in computer vision, particularly in domains humans are not accustomed to. As machine learning and artificial intelligence become more prominent, it is crucial these algorithms develop a sense of sight that is on par or exceeds human ability. For this reason, we have collected, cleaned, and parsed a large dataset of hand drawn doodles and compared multiple machine learning solutions to classify these images into 170 distinct categories. The best model we found achieved a Top-1 accuracy of 47.5%, significantly  surpassing human performance on the dataset, which stands at 41%.
				</p>
				<a class="arxiv-button" href="" target="_blank">arXiv</a>
			</div>
		</div>
	</section>
</body>
</html>